{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e956594e",
   "metadata": {},
   "source": [
    "To Make CSV File and check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2204a2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Renamed_OK: 100%|██████████| 1002/1002 [00:00<00:00, 2397.77it/s]\n",
      "Processing Renamed_Not_OK: 100%|██████████| 4699/4699 [00:01<00:00, 2810.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ DATA CLEANING REPORT ================\n",
      "Total images scanned        : 5701\n",
      "Corrupt images removed      : 0\n",
      "Duplicate images removed    : 0\n",
      "Clean images used           : 5701\n",
      "\n",
      "--- Per Class Breakdown ---\n",
      "OK Images:\n",
      "  Total     : 1002\n",
      "  Corrupt   : 0\n",
      "  Duplicate : 0\n",
      "  Clean     : 1002\n",
      "\n",
      "NOT OK Images:\n",
      "  Total     : 4699\n",
      "  Corrupt   : 0\n",
      "  Duplicate : 0\n",
      "  Clean     : 4699\n",
      "\n",
      "CSV saved as: train.csv\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# >>>>>>>>>>>> ADD YOUR DATASET PATHS HERE <<<<<<<<<<<<<<<\n",
    "# =========================================================\n",
    "OK_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Renamed_OK\"\n",
    "NOT_OK_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Renamed_Not_OK\"\n",
    "\n",
    "OUTPUT_CSV = \"train.csv\"\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "def is_image_corrupt(image_path):\n",
    "    \"\"\"\n",
    "    Returns True if image is corrupt, else False\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img.verify()\n",
    "        return False\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "\n",
    "def compute_image_hash(image_path):\n",
    "    \"\"\"\n",
    "    Computes SHA256 hash of image file for duplicate detection\n",
    "    \"\"\"\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            sha256.update(chunk)\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "\n",
    "def process_folder(folder_path, label, seen_hashes, records, stats):\n",
    "    image_files = os.listdir(folder_path)\n",
    "\n",
    "    for img_name in tqdm(image_files, desc=f\"Processing {os.path.basename(folder_path)}\"):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "\n",
    "        stats[\"total\"] += 1\n",
    "        stats[\"per_class\"][label][\"total\"] += 1\n",
    "\n",
    "        # 1. Corrupt image check\n",
    "        if is_image_corrupt(img_path):\n",
    "            stats[\"corrupt\"] += 1\n",
    "            stats[\"per_class\"][label][\"corrupt\"] += 1\n",
    "            continue\n",
    "\n",
    "        # 2. Duplicate image check\n",
    "        img_hash = compute_image_hash(img_path)\n",
    "        if img_hash in seen_hashes:\n",
    "            stats[\"duplicate\"] += 1\n",
    "            stats[\"per_class\"][label][\"duplicate\"] += 1\n",
    "            continue\n",
    "\n",
    "        seen_hashes.add(img_hash)\n",
    "\n",
    "        # 3. Store clean record\n",
    "        image_id = os.path.splitext(img_name)[0]\n",
    "        records.append({\n",
    "            \"ID\": image_id,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "        stats[\"clean\"] += 1\n",
    "        stats[\"per_class\"][label][\"clean\"] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    seen_hashes = set()\n",
    "    records = []\n",
    "\n",
    "    stats = {\n",
    "        \"total\": 0,\n",
    "        \"corrupt\": 0,\n",
    "        \"duplicate\": 0,\n",
    "        \"clean\": 0,\n",
    "        \"per_class\": {\n",
    "            1: defaultdict(int),  # OK\n",
    "            0: defaultdict(int)   # NOT OK\n",
    "        }\n",
    "    }\n",
    "\n",
    "    process_folder(OK_DIR, label=1, seen_hashes=seen_hashes, records=records, stats=stats)\n",
    "    process_folder(NOT_OK_DIR, label=0, seen_hashes=seen_hashes, records=records, stats=stats)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df.drop_duplicates(subset=\"ID\", inplace=True)\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "    # ================== SUMMARY REPORT ==================\n",
    "    print(\"\\n================ DATA CLEANING REPORT ================\")\n",
    "    print(f\"Total images scanned        : {stats['total']}\")\n",
    "    print(f\"Corrupt images removed      : {stats['corrupt']}\")\n",
    "    print(f\"Duplicate images removed    : {stats['duplicate']}\")\n",
    "    print(f\"Clean images used           : {len(df)}\")\n",
    "\n",
    "    print(\"\\n--- Per Class Breakdown ---\")\n",
    "    print(f\"OK Images:\")\n",
    "    print(f\"  Total     : {stats['per_class'][1]['total']}\")\n",
    "    print(f\"  Corrupt   : {stats['per_class'][1]['corrupt']}\")\n",
    "    print(f\"  Duplicate : {stats['per_class'][1]['duplicate']}\")\n",
    "    print(f\"  Clean     : {stats['per_class'][1]['clean']}\")\n",
    "\n",
    "    print(f\"\\nNOT OK Images:\")\n",
    "    print(f\"  Total     : {stats['per_class'][0]['total']}\")\n",
    "    print(f\"  Corrupt   : {stats['per_class'][0]['corrupt']}\")\n",
    "    print(f\"  Duplicate : {stats['per_class'][0]['duplicate']}\")\n",
    "    print(f\"  Clean     : {stats['per_class'][0]['clean']}\")\n",
    "\n",
    "    print(f\"\\nCSV saved as: {OUTPUT_CSV}\")\n",
    "    print(\"======================================================\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce75748",
   "metadata": {},
   "source": [
    "Image resized to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95bad3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing OK images: 100%|██████████| 1002/1002 [00:04<00:00, 204.52it/s]\n",
      "Resizing NOT OK images: 100%|██████████| 4699/4699 [00:26<00:00, 176.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All images resized to 256x256 and saved in:\n",
      "C:\\Users\\maila\\Desktop\\Defect_Detection\\Combined_Resized_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= ADD PATHS HERE =================\n",
    "OK_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Renamed_Ok\"\n",
    "NOT_OK_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Renamed_Not_OK\"\n",
    "\n",
    "OUTPUT_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Combined_Resized_256\"\n",
    "TARGET_SIZE = (256, 256)\n",
    "# ==================================================\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "VALID_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "\n",
    "def resize_and_save(folder_path, desc_name):\n",
    "    image_files = [\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if f.lower().endswith(VALID_EXTENSIONS)\n",
    "    ]\n",
    "\n",
    "    for img_name in tqdm(image_files, desc=f\"Resizing {desc_name} images\"):\n",
    "        src_path = os.path.join(folder_path, img_name)\n",
    "        dst_path = os.path.join(OUTPUT_DIR, img_name)  # SAME NAME, NO PREFIX\n",
    "\n",
    "        try:\n",
    "            with Image.open(src_path) as img:\n",
    "                img = img.convert(\"RGB\")\n",
    "                img_resized = img.resize(TARGET_SIZE, Image.BILINEAR)\n",
    "                img_resized.save(dst_path)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "\n",
    "# Resize OK images\n",
    "resize_and_save(OK_DIR, desc_name=\"OK\")\n",
    "\n",
    "# Resize NOT OK images\n",
    "resize_and_save(NOT_OK_DIR, desc_name=\"NOT OK\")\n",
    "\n",
    "print(\"\\nAll images resized to 256x256 and saved in:\")\n",
    "print(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc01790",
   "metadata": {},
   "source": [
    "Normalizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa7e67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing images: 100%|██████████| 5701/5701 [01:47<00:00, 53.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All images normalized and saved to:\n",
      "C:\\Users\\maila\\Desktop\\Defect_Detection\\Normalised_Image_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= ADD PATHS HERE =================\n",
    "IMAGE_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Combined_Resized_256\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Normalised_Image_256\"\n",
    "# ==================================================\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "VALID_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "# Collect all image files\n",
    "image_files = [\n",
    "    f for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith(VALID_EXTENSIONS)\n",
    "]\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    raise ValueError(\"No images found in the folder.\")\n",
    "\n",
    "for img_name in tqdm(image_files, desc=\"Normalizing images\"):\n",
    "    img_path = os.path.join(IMAGE_DIR, img_name)\n",
    "    save_path = os.path.join(OUTPUT_DIR, img_name)\n",
    "\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "            img_np = np.asarray(img).astype(np.float32)\n",
    "\n",
    "            # Min-Max Normalization\n",
    "            min_val = img_np.min()\n",
    "            max_val = img_np.max()\n",
    "\n",
    "            if max_val > min_val:\n",
    "                img_norm = (img_np - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                img_norm = img_np  # edge case: constant image\n",
    "\n",
    "            # Convert back to uint8 before saving\n",
    "            img_norm = (img_norm * 255).astype(np.uint8)\n",
    "\n",
    "            Image.fromarray(img_norm).save(save_path)\n",
    "\n",
    "    except Exception:\n",
    "        # Skip unreadable or corrupt images safely\n",
    "        continue\n",
    "\n",
    "print(\"\\nAll images normalized and saved to:\")\n",
    "print(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5613f8a1",
   "metadata": {},
   "source": [
    "Standardizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea5e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing images: 100%|██████████| 5701/5701 [00:21<00:00, 265.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All images standardized and saved to:\n",
      "C:\\Users\\maila\\Desktop\\Defect_Detection\\Standardized_Image_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= ADD PATHS HERE =================\n",
    "IMAGE_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Combined_Resized_256\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Standardized_Image_256\"\n",
    "# ==================================================\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "VALID_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "image_files = [\n",
    "    f for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith(VALID_EXTENSIONS)\n",
    "]\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    raise ValueError(\"No images found in the folder.\")\n",
    "\n",
    "for img_name in tqdm(image_files, desc=\"Standardizing images\"):\n",
    "    img_path = os.path.join(IMAGE_DIR, img_name)\n",
    "    save_path = os.path.join(OUTPUT_DIR, img_name)\n",
    "\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "            img_np = np.asarray(img).astype(np.float32)\n",
    "\n",
    "            mean = img_np.mean()\n",
    "            std = img_np.std()\n",
    "\n",
    "            if std > 0:\n",
    "                img_std = (img_np - mean) / std\n",
    "            else:\n",
    "                img_std = img_np  # edge case\n",
    "\n",
    "            # Re-scale standardized image for saving (visualization only)\n",
    "            img_std_min = img_std.min()\n",
    "            img_std_max = img_std.max()\n",
    "\n",
    "            img_std = (img_std - img_std_min) / (img_std_max - img_std_min)\n",
    "            img_std = (img_std * 255).astype(np.uint8)\n",
    "\n",
    "            Image.fromarray(img_std).save(save_path)\n",
    "\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "print(\"\\nAll images standardized and saved to:\")\n",
    "print(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec2044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in folder: 5701\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ============== ADD PATH HERE ==============\n",
    "IMAGE_DIR = r\"C:\\Users\\maila\\Desktop\\Defect_Detection\\Normalised_Image_256\"\n",
    "# ===========================================\n",
    "\n",
    "VALID_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "image_count = sum(\n",
    "    1 for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith(VALID_EXTENSIONS)\n",
    ")\n",
    "\n",
    "print(\"Number of images in folder:\", image_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2193a8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
